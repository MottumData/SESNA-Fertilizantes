{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Listado de Listado de Beneficiarios 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores\n",
    "- José Luis Delgado Dávara\n",
    "- Arturo Ortiz Aguilar\n",
    "- Beltrán Valle Gutiérrez-Cortines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importante leer para entender\n",
    "\n",
    "En este Notebook se trabaja con 3 listados importantes:\n",
    "\n",
    "1. beneficiarios_20 -> Dataset con el listado de TODOS los beneficiarios de 2020.\n",
    "2. Estados_Beneficiarios_2019_2022 -> Dataset sólo con los estados *únicos* encontrados en el dataset anterior.\n",
    "3. Diccionario -> Emparejamiento entre ambos listados de beneficiarios\n",
    "4. Dataset_Inegi -> Catálogo obtenido de Inegi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    De esta manera tenemos el texto sin espacios blancos extra y sobre todo con todas las palabras con capitalización correcta.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = text.strip()  # Eliminate white spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = unidecode.unidecode(text)  # Remove accents\n",
    "    text = re.sub('-.*-', '', text) #Remove what is in between - -\n",
    "    text = re.sub('\\s+', ' ', text)  # Eliminate extra white spaces\n",
    "    text = re.sub('^\\s+|\\s+?$', '', text)  # Eliminate spaces at the beginning and end\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lectura y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Beneficiarios 2020\n",
    "\n",
    "Obtenemos el listado único de localidades y listado único de municipios con sus claves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20 = pd.read_csv('../../data/productores_beneficiarios 2019-2022/listado_beneficiarios_fertilizantes_2020.csv', encoding='utf-8', skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20 = beneficiarios_20[~((beneficiarios_20['ENTIDAD'] == 'NACIONAL') & (beneficiarios_20['MUNICIPIO'] == 'NACIONAL') & (beneficiarios_20['LOCALIDAD'] == 'NACIONAL'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = beneficiarios_20[beneficiarios_20.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20['ENTIDAD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropeamos los tres valores nulos debido a que las rows enteras salen como nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las localidades únicas en el dataset.\n",
    "Localidades_20 = beneficiarios_20[['ENTIDAD', 'MUNICIPIO', 'LOCALIDAD']]\n",
    "Localidades_20 = Localidades_20.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Localidades_20['ENTIDAD_c_benef'] = Localidades_20['ENTIDAD'].apply(clean_text)\n",
    "Localidades_20['MUNICIPIO_c_benef'] = Localidades_20['MUNICIPIO'].apply(clean_text)\n",
    "Localidades_20['LOCALIDAD_c_benef'] = Localidades_20['LOCALIDAD'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las dos keys de beneficiarios 2019\n",
    "Localidades_20['KEY_benef_mun'] = Localidades_20['ENTIDAD_c_benef'].astype(str) + '-' + Localidades_20[\n",
    "    'MUNICIPIO_c_benef'].astype(str)\n",
    "Localidades_20['KEY_benef_loc'] = Localidades_20['ENTIDAD_c_benef'].astype(str) + '-' + Localidades_20[\n",
    "    'MUNICIPIO_c_benef'].astype(str) + '-' + Localidades_20['LOCALIDAD_c_benef'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Localidades_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las localidades únicas en el dataset.\n",
    "Municipios_20 = beneficiarios_20[['ENTIDAD', 'MUNICIPIO']]\n",
    "Municipios_20 = Municipios_20.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos la limpieza de los datos\n",
    "Municipios_20['ENTIDAD_c_benef'] = Municipios_20['ENTIDAD'].apply(clean_text)\n",
    "Municipios_20['MUNICIPIO_c_benef'] = Municipios_20['MUNICIPIO'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las dos keys de beneficiarios \n",
    "Municipios_20['KEY_benef_mun'] = Municipios_20['ENTIDAD_c_benef'].astype(str) + '-' + Municipios_20[\n",
    "    'MUNICIPIO_c_benef'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Municipios_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Municipios_20.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 INEGI 2020\n",
    "\n",
    "Obtener listado único de municipios y listado único de localidades de inegi de 2020 con sus claves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_inegi_2020 = '../../data/inegi/dataset_inegi_clean_2020.csv'\n",
    "#dataset_inegi_clean = pd.read_csv(path_dataset_inegi_2022, encoding='utf-8', dtype={'CVE_ENT': str, 'CVE_MUN': str, 'CVE_LOC': str})\n",
    "dataset_inegi_2020 = pd.read_csv(path_dataset_inegi_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inegi_2020['CVE_ENT'] = dataset_inegi_2020['CVE_ENT'].astype(str).str.zfill(2)\n",
    "dataset_inegi_2020['CVE_MUN'] = dataset_inegi_2020['CVE_MUN'].astype(str).str.zfill(3)\n",
    "dataset_inegi_2020['CVE_LOC'] = dataset_inegi_2020['CVE_LOC'].astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 INEGI 2020 Municipios únicos para cada año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inegi_2020['KEY_inegi_municipio'] = dataset_inegi_2020['Entidad_c_inegi'].astype(str) + '-' + dataset_inegi_2020[\n",
    "    'Municipio_c_inegi'].astype(str) \n",
    "dataset_inegi_2020['KEY_inegi_localidad'] = dataset_inegi_2020['Municipio_c_inegi'].astype(str) + '-' + dataset_inegi_2020['Localidad_c_inegi'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUEMUN_2020 = dataset_inegi_2020.drop(columns=[\"CVE_LOC\", \"Localidad_inegi\", \"Localidad_c_inegi\", \"KEY_inegi_localidad\", \"POB_TOTAL\"])\n",
    "INEGI_UNIQUEMUN_2020 = INEGI_UNIQUEMUN_2020.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUEMUN_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUEMUN_2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUEMUN_2020.drop_duplicates(subset='KEY_inegi_municipio', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Diccionario de los datasets de INEGI Y LISTADO BENEFICIARIOS 2020\n",
    "\n",
    "El objetivo de esta sección es crear dos diccionarios de códigos según BENEFICIARIOS-MUNICIPIOS_INEGI y otro BENEFICIARIOS-LOCALIDADES_INEGI, para cada uno de los estados encontrados en inegi_2020, en este caso el número de keys es menor con lo cual no nos hará falta dividir por estado.\n",
    "\n",
    "Para ello haremos un Left join entre Localidades_20 y el dataset de INEGI correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una función para encontrar la mejor coincidencia difusa con límites entre 85 y 100 de coincidencia\n",
    "def fuzzy_merge_benef2019_2022(df_benef, df_inegi, key1, key2, threshold=85, limit=1):\n",
    "    \"\"\"\n",
    "    df_inegi: DataFrame de la izquierda (el DataFrame principal)\n",
    "    df_prod: DataFrame de la derecha (el DataFrame con el que se quiere hacer el join)\n",
    "    key1: Columna de la clave en df_inegi\n",
    "    key2: Columna de la clave en df_prod\n",
    "    threshold: Umbral de coincidencia difusa\n",
    "    limit: Número de coincidencias a encontrar\n",
    "    \"\"\"\n",
    "    s = df_inegi[key2].tolist()\n",
    "    \n",
    "    # Encontrar las mejores coincidencias para cada clave en df_inegi\n",
    "    matches = df_benef[key1].apply(lambda x: process.extractOne(x, s, score_cutoff=threshold))\n",
    "\n",
    "\n",
    "    # Crear una columna con las mejores coincidencias\n",
    "    df_benef['best_match'] = [match[0] if match else None for match in matches]\n",
    "    \n",
    "    df_benef['match_score'] = [match[1] if match else None for match in matches]\n",
    "    \n",
    "\n",
    "    # Hacer el merge con las mejores coincidencias\n",
    "    df_merged = pd.merge(df_benef, df_inegi, left_on='best_match', right_on=key2, how='left',\n",
    "                         suffixes=('_benef', '_inegi'))\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_20 = fuzzy_merge_benef2019_2022(Municipios_20, INEGI_UNIQUEMUN_2020, 'KEY_benef_mun', 'KEY_inegi_municipio')\n",
    "diccionario_MUN_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_20.drop(columns=['ENTIDAD', 'MUNICIPIO', 'ENTIDAD_c_benef', 'MUNICIPIO_c_benef', 'Entidad_c_inegi',\n",
    "       'Municipio_c_inegi'], inplace=True)\n",
    "diccionario_MUN_20.drop_duplicates(subset='KEY_benef_mun', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_20.to_csv('../../data/productores_beneficiarios 2019-2022/diccionarios_E3/diccionario_MUN_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_20_simple = pd.read_csv('../../data/productores_beneficiarios 2019-2022/diccionarios_E3/diccionario_MUN_20_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_21_simple = diccionario_MUN_20_simple.drop_duplicates(subset='KEY_inegi_municipio', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_21_simple = diccionario_MUN_20_simple.drop_duplicates(subset='KEY_inegi_municipio', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_20_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_MUN_20_simple.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE\n",
    "\n",
    "Armamos por partes el dataset definitivo:\n",
    "1. Juntamos beneficiarios_19 con el diccionario simple. (listado_beneficiario_parte_I)\n",
    "2. Al df anterior juntamos las claver provenientes del catálogo de Inegi. (listado_beneficiario_parte_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beneficiarios_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una variable KEY en listado de productores y el diccionario para hacer el join\n",
    "\n",
    "# Clean listado beneficiarios\n",
    "beneficiarios_20['ESTADO_Clean'] = beneficiarios_20['ENTIDAD'].apply(clean_text)\n",
    "beneficiarios_20['MUNICIPIO_Clean'] = beneficiarios_20['MUNICIPIO'].apply(clean_text)\n",
    "\n",
    "# Create KEY in listado beneficiarios\n",
    "beneficiarios_20['Estado-mun-KEY'] = beneficiarios_20['ESTADO_Clean'].astype(str) + '-' + beneficiarios_20[\n",
    "    'MUNICIPIO_Clean'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer el join de la Parte I\n",
    "listado_beneficiarios_parte_I = pd.merge(beneficiarios_20, diccionario_MUN_20_simple, left_on=\"Estado-mun-KEY\",\n",
    "                                        right_on=\"KEY_benef_mun\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer el join de la Parte II\n",
    "listado_beneficiarios_parte_II = pd.merge(listado_beneficiarios_parte_I, INEGI_UNIQUEMUN_2020, left_on=\"KEY_inegi_municipio\",\n",
    "                                        right_on=\"KEY_inegi_municipio\", how='left', suffixes=('_benef', '_inegi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II = listado_beneficiarios_parte_II.drop(columns=['ESTADO_Clean', 'MUNICIPIO_Clean', 'Estado-mun-KEY', 'KEY_inegi_municipio', 'Entidad_c_inegi','Municipio_c_inegi', 'ESTRATIFICACIÓN', 'PROGRAMA', 'COMPONENTE', 'SUBCOMPONENTE', 'APOYO', 'ACTIVIDAD', 'ESLABÓN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II.to_csv('../../data/listados_completos/listado_beneficiarios_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Join por entidad (Divide y Vencerás)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match = pd.read_csv('../../data/listados_completos/listado_beneficiarios_2020_match.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match[listado_beneficiarios_2020_match['LOCALIDAD'] == 'NACIONAL'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las localidades únicas en el dataset.\n",
    "listado_beneficiarios_2020_match = listado_beneficiarios_2020_match.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match['ENTIDAD_c_benef'] = listado_beneficiarios_2020_match['ENTIDAD'].apply(clean_text)\n",
    "listado_beneficiarios_2020_match['MUNICIPIO_c_benef'] = listado_beneficiarios_2020_match['MUNICIPIO'].apply(clean_text)\n",
    "listado_beneficiarios_2020_match['LOCALIDAD_c_benef'] = listado_beneficiarios_2020_match['LOCALIDAD'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match['KEY_benef_loc'] = listado_beneficiarios_2020_match['MUNICIPIO_c_benef'].astype(str) + '-' + listado_beneficiarios_2020_match['LOCALIDAD_c_benef'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match.ENTIDAD.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Join de localidades - GUERRERO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos creando los datasets por entiedad del dataset de beneficiarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ['GUERRERO', 'MORELOS', 'TLAXCALA', 'PUEBLA', 'Guerrero', 'Puebla']\n",
    "\n",
    "# Dictionary to hold DataFrames\n",
    "dataframes_dict = {}\n",
    "\n",
    "for entity in entities:\n",
    "    variable_name = f\"Localidades_20_{entity.upper().replace(' ', '_')}\"\n",
    "    dataframe = listado_beneficiarios_2020_match[listado_beneficiarios_2020_match[\"ENTIDAD\"] == entity]\n",
    "    \n",
    "    # Check if the DataFrame for this entity already exists in the dictionary\n",
    "    if variable_name in dataframes_dict:\n",
    "        # If it exists, concatenate the new DataFrame with the existing one\n",
    "        dataframes_dict[variable_name] = pd.concat([dataframes_dict[variable_name], dataframe])\n",
    "    else:\n",
    "        # If it does not exist, create a new entry in the dictionary\n",
    "        dataframes_dict[variable_name] = dataframe\n",
    "\n",
    "# Define each DataFrame as a separate variable\n",
    "for name, df in dataframes_dict.items():\n",
    "    globals()[name] = df\n",
    "    print(f\"{name} defined with shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Localidades_20_Guerrero = listado_beneficiarios_2020_match[listado_beneficiarios_2020_match['ENTIDAD'] == 'Guerrero']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Diccionarios de Inegi por entidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../../data/productores_beneficiarios 2019-2022/diccionarios_E3/2020'\n",
    "\n",
    "# Listar todos los archivos en la carpeta\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filtrar solo los archivos CSV\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Leer cada archivo CSV y almacenar en variables separadas\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # Crear un nombre de variable dinámicamente eliminando la extensión .csv\n",
    "    var_name = file_name.replace('.csv', '')\n",
    "    # Leer el archivo CSV y asignar el DataFrame a la variable\n",
    "    globals()[var_name] = pd.read_csv(file_path)\n",
    "\n",
    "# Opcional: Imprimir el nombre de las variables creadas y la cantidad de filas y columnas de cada DataFrame\n",
    "for file_name in csv_files:\n",
    "    var_name = file_name.replace('.csv', '')\n",
    "    df = globals()[var_name]\n",
    "    print(f'{var_name}: {df.shape[0]} filas, {df.shape[1]} columnas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUELOC_2020_guerrero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Localidades_20_GUERRERO_parte_I = fuzzy_merge_benef2019_2022(Localidades_20_GUERRERO, INEGI_UNIQUELOC_2020_guerrero, 'KEY_benef_loc', 'KEY_inegi_localidad')\n",
    "Localidades_20_GUERRERO_parte_I.shape\n",
    "\n",
    "Localidades_20_PUEBLA_parte_I = fuzzy_merge_benef2019_2022(Localidades_20_PUEBLA, INEGI_UNIQUELOC_2020_puebla, 'KEY_benef_loc', 'KEY_inegi_localidad')\n",
    "Localidades_20_PUEBLA_parte_I.shape\n",
    "\n",
    "Localidades_20_MORELOS_parte_I = fuzzy_merge_benef2019_2022(Localidades_20_MORELOS, INEGI_UNIQUELOC_2020_morelos, 'KEY_benef_loc', 'KEY_inegi_localidad')\n",
    "Localidades_20_MORELOS_parte_I.shape\n",
    "\n",
    "Localidades_20_TLAXCALA_parte_I = fuzzy_merge_benef2019_2022(Localidades_20_TLAXCALA, INEGI_UNIQUELOC_2020_tlaxcala, 'KEY_benef_loc', 'KEY_inegi_localidad')\n",
    "Localidades_20_TLAXCALA_parte_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets vertically\n",
    "diccionario_LOC_20 = pd.concat([\n",
    "    Localidades_20_GUERRERO_parte_I,\n",
    "    Localidades_20_PUEBLA_parte_I,\n",
    "    Localidades_20_MORELOS_parte_I,\n",
    "    Localidades_20_TLAXCALA_parte_I\n",
    "], axis=0)\n",
    "\n",
    "# Check the shape of the concatenated DataFrame\n",
    "diccionario_LOC_20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20.drop(columns=['BENEFICIARIO', 'ZONA', 'ENTIDAD', 'MUNICIPIO', 'LOCALIDAD', 'PRODUCTO',\n",
    "       'FECHA', 'MONTO FEDERAL', 'CICLO AGRÍCOLA', 'ENTIDAD_c_benef',\n",
    "       'MUNICIPIO_c_benef', 'LOCALIDAD_c_benef', 'best_match', 'CVE_ENT', 'Entidad_inegi', 'CVE_MUN', 'Municipio_inegi',\n",
    "       'CVE_LOC', 'Localidad_inegi', 'POB_TOTAL', 'Entidad_c_inegi',\n",
    "       'Municipio_c_inegi', 'Localidad_c_inegi'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20.to_csv('../../data/productores_beneficiarios 2019-2022/diccionarios_E3/diccionario_LOC_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Diccionarios de localidades y merge respectivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos leyendo el diccionario_LOC_20_simple, el cual solo tiene key_benef_mun y key_inegi_municipio manipulada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Intentar leer el archivo CSV con diferentes configuraciones de lectura\n",
    "try:\n",
    "    diccionario_LOC_20_simple = pd.read_csv('../../data/productores_beneficiarios 2019-2022/diccionarios_E3/diccionario_LOC_20_simple.csv', encoding='cp1252', \n",
    "                          delimiter=';')\n",
    "    #diccionario_LOC_21_simple.drop(columns=['ValidaciÃ³n', 'Propuesta'], inplace=True)\n",
    "    print(diccionario_LOC_20_simple.head())\n",
    "except pd.errors.ParserError as e:\n",
    "    print(\"Error al leer el archivo CSV:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20_simple.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20_simple.rename(columns={'ï»¿KEY_benef_loc': 'KEY_benef_loc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20_simple.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_LOC_20_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match['MUNICIPIO_Clean'] = listado_beneficiarios_2020_match['MUNICIPIO'].apply(clean_text)\n",
    "listado_beneficiarios_2020_match['LOCALIDAD_Clean'] = listado_beneficiarios_2020_match['LOCALIDAD'].apply(clean_text)\n",
    "\n",
    "# Create KEY in listado beneficiarios\n",
    "listado_beneficiarios_2020_match['Municipio-loc-KEY'] = listado_beneficiarios_2020_match['MUNICIPIO_Clean'].astype(str) + '-' + listado_beneficiarios_2020_match[\n",
    "    'LOCALIDAD_Clean'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer merge entre listado_beneficiarios_parte_II, y diccionario_LOC_22_simple. En este merge cogemos el dataset con los municipios corregidos previamente y ejecutamos el merge de manera que nos traemos las key_inegi_localidad corregidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUELOC_2020 = dataset_inegi_2020.drop(columns=['Entidad_c_inegi', 'Municipio_c_inegi',\n",
    "       'Localidad_c_inegi', 'POB_TOTAL'])\n",
    "INEGI_UNIQUELOC_2020 = INEGI_UNIQUELOC_2020.drop_duplicates(subset='KEY_inegi_localidad', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INEGI_UNIQUELOC_2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marcar todos los duplicados en las columnas 'columna1' y 'columna2' como True\n",
    "duplicados = listado_beneficiarios_2020_match.duplicated()\n",
    "\n",
    "# Filtrar el DataFrame original para mostrar solo los duplicados\n",
    "df_duplicados = listado_beneficiarios_2020_match[duplicados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_2020_match['Municipio-loc-KEY'] = listado_beneficiarios_2020_match['Municipio-loc-KEY'].str.strip().str.lower()\n",
    "diccionario_LOC_20_simple['KEY_benef_loc'] = diccionario_LOC_20_simple['KEY_benef_loc'].str.strip().str.lower()\n",
    "\n",
    "# Asegurar que las keys son del mismo tipo\n",
    "listado_beneficiarios_2020_match['Municipio-loc-KEY'] = listado_beneficiarios_2020_match['Municipio-loc-KEY'].astype(str)\n",
    "diccionario_LOC_20_simple['KEY_benef_loc'] = diccionario_LOC_20_simple['KEY_benef_loc'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer el join de la Parte I\n",
    "listado_beneficiarios_parte_I_localidades = pd.merge(listado_beneficiarios_2020_match, diccionario_LOC_20_simple, left_on=\"Municipio-loc-KEY\",\n",
    "                                         right_on=\"KEY_benef_loc\", how='left', suffixes=('_benef', '_inegi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I_localidades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marcar todos los duplicados en las columnas 'columna1' y 'columna2' como True\n",
    "duplicados = listado_beneficiarios_parte_I_localidades.duplicated()\n",
    "\n",
    "# Filtrar el DataFrame original para mostrar solo los duplicados\n",
    "df_duplicados = listado_beneficiarios_parte_I_localidades[duplicados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I_localidades.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I_localidades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_I_localidades.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming listado_beneficiarios_parte_II is your DataFrame\n",
    "rows_with_nan = listado_beneficiarios_parte_I_localidades[listado_beneficiarios_parte_I_localidades.isna().any(axis=1)]\n",
    "\n",
    "# rows_with_nan now contains only the rows with NaN values in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listado_beneficiarios_parte_I_localidades['KEY_inegi_localidad'].duplicated().sum())\n",
    "print(INEGI_UNIQUELOC_2020['KEY_inegi_localidad'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REVISAR ESTA PARTE (ARTURO)\n",
    "listado_beneficiarios_parte_II_localidades = pd.merge(listado_beneficiarios_parte_I_localidades, INEGI_UNIQUELOC_2020,\n",
    "                                          left_on=\"KEY_inegi_localidad\",\n",
    "                                          right_on=\"KEY_inegi_localidad\", how='left', suffixes=('_benef', '_inegi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming listado_beneficiarios_parte_II is your DataFrame\n",
    "rows_with_nan = listado_beneficiarios_parte_II_localidades[listado_beneficiarios_parte_II_localidades.isna().any(axis=1)]\n",
    "\n",
    "# rows_with_nan now contains only the rows with NaN values in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.drop(columns=['ENTIDAD', 'MUNICIPIO', 'LOCALIDAD',\n",
    "       'MUNICIPIO_Clean', 'LOCALIDAD_Clean', 'Municipio-loc-KEY', 'match_score', 'KEY_inegi_localidad',\n",
    "       'KEY_inegi_municipio',  'ENTIDAD_c_benef', 'MUNICIPIO_c_benef', 'LOCALIDAD_c_benef',\n",
    "       'KEY_benef_loc_benef', 'KEY_benef_loc_inegi', 'CVE_ENT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.rename(columns={'BENEFICIARIO': 'Nombre del beneficiario',\n",
    "                                                           'ZONA': 'Zona del país',\n",
    "                                                           'CVE_ENT_inegi': 'Clave de entidad',\n",
    "                                                            'Entidad_inegi': 'Entidad federativa',\n",
    "                                                            'CVE_MUN': 'Clave de municipio',\n",
    "                                                            'Municipio_inegi': 'Municipio',                                                           \n",
    "                                                            'CVE_LOC': 'Clave de localidad',\n",
    "                                                            'Localidad_inegi': 'Localidad',\n",
    "                                                            'PRODUCTO': 'Producto cultivado',\n",
    "                                                            'FECHA': 'Fecha de entrega del beneficio',\n",
    "                                                            'MONTO FEDERAL': 'Monto entregado',\n",
    "                                                            'CICLO AGRÍCOLA': 'Ciclo agrícola'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_beneficiarios_parte_II_localidades.to_csv('../../data/listados_completos/listado_beneficiarios_2020_localidades.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
